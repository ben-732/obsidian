In java, you are often going to be sorting collections rather than arrays. 

Expansion on 281 [[Advanced Data Structures]]

# Java Collections
## Interfaces
What can we do with the data?
The old school term is an abstract data-type but is now referred to as an interface or API

### List / Set / Map
#### List: 
We care about hte order in which the elements are added,
**Fast:** 
- Add/remove from the end of the list (Linked List, Dynamic Array)
- Random access (Dynamic Array)

**Slow:**
- Add  / Remove from the middle of the list
- Checking if an element is present in the list

#### Set
We care weather an element is present, not when it was added

#### Map (Dictionary)
We care if an element is present and what is its associated value
#### Set / Map
A set is a dummy implementation of map, however a map is not an implementation of set. They are mostly the same however and we generally consider set because it is simpler. 
## List

>[!info] Java List interface
>![[Pasted image 20230803134402.png]]

### FixedSizeList
```java
class FixedSizeList {
	private int data[];
	private int size;

	public FizedListSize(int n) {
		data = new int[n];
		size = 0;
	}

	public add(int val) {
		data[size] = val;
		size++;
	}

	public void remove(){
		size --;
	}

	public void set(int val, int index);
	public void get(int index);
	public int size();
}
```

This is a basic limited implementation of a list.

It has excellent running time. Most operations have $O(1)$ running time. 

However, it uses wastes a lot of memory if we only end up adding a small number of elements. And there is no way to expand the list. (the way memory works :(( )

### LinkedList
Implementation the same as 281.

Each node has a reference to the next and you can traverse the list to preform operations. 

This does not have the memory issues that the previous list has

>[!info]- Linked List running times
>![[Pasted image 20230803135306.png]]


### Double linked list
In a Double linked list, the nodes contain references to both the next and previous element. This allows us to quickly remove the last element in the list in $O(1)$ time. 

### Dynamic Array (ArrayList)
As covered previously, arrays are great fro get/set operations. But the capacity is pre determined upon creation. 

**Idea:** If we have reached the capacity, create a new array with double the capacity. 

This can be implemented with the java function `data = Arrays.copyOf(data, capacity)`

This method means that every operation has a complexity of $O(1)$ except for add which has a worst case complexity of $O(n)$ but only when you need to copy the data to a new array.

The cost of adding the $i^{th}$ element is $2^j +1$ if $i = 2^j +1$, otherwise is it just $1$
This first instance only occurs $\log n$ times. Therefore the cost of $n$ add operations is
$$\Large \sum^n_{i = 1} i + \sum^{\log n}_{j=0}2^j < 3n$$

This structure still has the issue of if the list grows to size $n$ and then we remove all but a few cells, we are still using $n$ cells. 
Python takes care of this for you, but other languages you need to implement it yourself. 
#### Amortised Complexity
Suppose we have two operations: **A** and **B**, We say that
- A has amortised complexity $T_{A}$
- B has amortised complexity $T_{B}$

If for any sequence of n operations: A, B, B, A, B, A, A, .....
of which, $n_{A}$ operations are $A$ and $n_{B}$ operations are $B$

The total running time in the worst case is $O(n_{a}\cdot T_{A} + n_{B} \cdot T_{B})$

So for the previous example, the amortised complexity of add with be $O(1)$ because when you run add $n$ times you get a time complexity of $<3n$ so $O(n)$
1




#### Shrinking dynamic array
Do the opposite of expanding the array. 

This creates a timing edge case of if you add and remove on the boundary of a size increase then the time complexity will suffer, roughly $O(n)$

**Idea:** To avoid this, only shrink the list when the list is 1/4 the size of the max length. 
Estimating the running time of this would be difficult, but amortised running time makes it much easier. 


#### #todo


## Set
Interface:
- **Add:** Adds the specified key to the set.,If it is not already present. 
- **remove:** 
- **Get**:

### Set via List 
#### Version 1
Store all the elements in a list
- `add(key)` Add the key to the end of the list $O(1)$
- `contains(key)` iterate through the list and check if the key is there $O(n)$
- `remove(key)` iterate through the list and remove **all** occurrences $O(n)$

The set interface has no duplicates but is not the user's business how we implement the list interface as long as the outward facing behaviour is the same. This means that as long as remove gets rid of all occurrences, we get the expected behaviour and it is a valid implementation. 

#### Version 2
Store all the elements in a sorted list (Dynamic Array)
- `add(key)` Add  key to the list such that elements remain sorted $O(n)$
- `contains(key)` Binary search $O(\log n)$
- `remove(key)` Remove key from list $O(n)$

This is better than the first implementation, as it is important that contains is fast. 

### Tree set
Using a binary tree to store nodes. 
- `add(key)` Try to find the key and if its there do nothing, if its not there we will find a null and thats where it should go. $O(\log n)$
- `contains(key)` Search the binary tree $O(\log n)$
- `remove(key)` find the next biggest node:
	- Case 1, No descendants: set null
	- Case 2, one child: set parents branch to child
	- Case 3, 2 children: Find next largest node, remove it and make it parent

## Map
### Interface
- `put(String key, int value)` Associates specified value with key. If key is present, override the mapped value with a new one. 
- `get(String key)` Returns the value associated with the specified key
- `contains(String key)` Returns boolean if map contains specified key
- `removeKey(String key)` Removes key from map

### Key / Value
Value can be anything, String, int, Object

Key can by any object that implements the `Comparable` interface. 
- Given two keys we can tell weather they are equal and if not which one is smaller
- If A < B, and B < C, A < C

### Hash Maps
#### Hashing
A *dark magic* turns a data structure into a number

Keys are from a set, they are a 32 bit integer. 

Can be mapped into a much smaller universe of key by using modulus. 

We know that the number of keys is relatively small but we don't know what they're going to be ahead of time. 
>[!tip] Hash tables and DynamicArrays are the most common datastructures


## Priority Queue
- `add(Comparable element)`
- `findMax()` returns largest element
- `removeMax()` removes and returns the largest object

This uses the [[4. Sorting#Heapsort|heap data structure]]. Maintains all the elements in a Dynamic Array List
#implementable 
- `add()` Put the element at the end of the list then bubble it up (like in heapify)
- `findMax()` element at index 0
- `removeMax()`
	1. Swap the element at index 0 with the last element in the list
	2. Remove the last element 
	3. Fix the list
### Graphs interface
#implementable 
For later, working with graphs?
This uses key value pairs and also implements a decrease value that can decrease the value of a given key, provided you enter a value lower than the pre existing value